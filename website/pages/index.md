## What is the Open AI index?
The Open AI index is an evidence-based framework to evaluate the openness of generative AI systems.

## Why is openness important?
An open and critical context where knowledge is shared, is crucial to fuel innovation in the (still early stages) of complex and impactful technologies like (generative) AI. Openness can help making sure innovation is not only serving commercial interests, but can push beyond to serve us all with its full potential.

[Read more](/readmore)

## What has openness to do with international regulations?
In 2024, the AI landscape will be shaken up by the EU's AI Act, the world's first comprehensive AI law, with a projected impact comparable to GDPR. To keep space for innovation, the Act includes exemptions for models released under open licenses. The problem of the Act is that ‘open’ is not defined and outsourced to a (yet to be established) EU AI Office.

[Read more](/readmore)

## What are the risks when the definition of ‘open’ is still _open_?
The big risk is that companies will claim to be open (by ie. using an open source license for a single aspect) to benefit from the exemptions on all aspects of their activities. This is called ‘open-washing’. There are numerous examples of this happening.

[Read more](/readmore)

## What did we do?
We created an evidence-based framework that distinguishes 14 dimensions of openness, from training datasets to scientific and technical documentation and from licensing to access methods. We published our research in a [paper](/paper). The data is continuously updated and publicly available via our [GitHub repository](/github). More importantly: [**contributions are encouraged**](/contribute). The website you’re currently reading is providing a user-friendly interface for the data from the Github repository and gives extra contextual information to a wider audience.

[Read more](/readmore)

## Why did we do this?
Evidence-based openness assessment can help foster a generative AI landscape in which models can be effectively regulated, model providers can be held accountable, scientists can scrutinise generative AI, and end users can make informed decisions.